{"cells":[{"cell_type":"markdown","metadata":{"id":"CyurDtxqHT0o"},"source":["# **Use YOLO-cls !**"]},{"cell_type":"markdown","metadata":{"id":"WE6nWiH8-i9q"},"source":["## 0.미션\n"]},{"cell_type":"markdown","metadata":{"id":"53bSTpVT-n_Y"},"source":["### (1) 미션1\n","여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"DBjsZP8C-2Ra"},"source":["### (2) 미션2\n","데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"WkDv7UfdYOgg"},"source":["## 1.환경설정"]},{"cell_type":"markdown","metadata":{"id":"mIxbiQ8wYOcy"},"source":["* 세부 요구사항\n","    - 경로 설정 : 구글콜랩\n","        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n","        * 데이터 파일을 복사해 넣습니다.\n","        * 필요하다고 판단되는 라이브러리를 추가하세요."]},{"cell_type":"markdown","metadata":{"id":"XIjpXC-xYHh3"},"source":["### (1) 경로 설정"]},{"cell_type":"markdown","metadata":{"id":"m6qgvZMSYcoX"},"source":["* 구글 드라이브 연결"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"imfft4dGGJ2E","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"error","timestamp":1730435512185,"user_tz":-540,"elapsed":122059,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"cc5b4435-34d3-4672-d8c6-a9396f534a83"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPngJ_nwZPRC","executionInfo":{"status":"aborted","timestamp":1730435512189,"user_tz":-540,"elapsed":16,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"outputs":[],"source":["path = '/content/drive/MyDrive/project4'"]},{"cell_type":"markdown","metadata":{"id":"SNEKwf_LY0JB"},"source":["### (2) 라이브러리 설치 및 불러오기"]},{"cell_type":"markdown","metadata":{"id":"xPwDW6e_Y0Fa"},"source":["* 라이브러리 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4dS7tW-Zwrx","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1730435512189,"user_tz":-540,"elapsed":11,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"outputs":[],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"Eg0gCl9Yatak"},"source":["## 2.미션1"]},{"cell_type":"markdown","metadata":{"id":"hPvTHwTmbKR5"},"source":["여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"6rXSONrsatd5"},"source":["### (1) 데이터셋 불러오기"]},{"cell_type":"markdown","metadata":{"id":"VXLqxwNaathI"},"source":["* **세부 요구사항**\n","    - 데이터셋을 불러옵니다.\n","        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n","            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n","                - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","            2. 여러분의 얼굴 이미지 데이터셋\n","                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n","                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n","    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n","        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n","        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, zipfile"]},{"cell_type":"code","source":["import os\n","import zipfile"],"metadata":{"id":"QFdzFmXBxgsH","executionInfo":{"status":"aborted","timestamp":1730435512190,"user_tz":-540,"elapsed":11,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6OntGw5H-C3q"},"source":["#### 1) 본인 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bFq5L4aAeQHr","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1730422293652,"user_tz":-540,"elapsed":405,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"0004d1a3-e7a1-4148-85c8-e679153e94a3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/project4/Datasets/Keras/my_face_exam.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["data_myFace = os.path.join(path, 'Datasets/Keras/my_face_exam.zip')\n","data_myFace"]},{"cell_type":"code","source":["## Colab에 생성할 본인 얼굴 폴더 경로\n","extract_folder = '/content/my_face'\n","\n","## 위의 경로에 폴더가 없을 때 생성\n","if not os.path.exists(extract_folder) :\n","    os.makedirs(extract_folder)\n","\n","## 위의 경로에 압축을 해제\n","with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n","    file_list = zip_ref.namelist()\n","\n","    for f in file_list :\n","        if not f.endswith('/') and f.lower().endswith('.jpg') :\n","            file_name = os.path.basename(f)\n","\n","            if not file_name.startswith('._') :\n","                d_path = os.path.join(extract_folder, file_name)\n","\n","                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n","                    target.write(source.read())"],"metadata":{"id":"6RkWLv0XxlZR","executionInfo":{"status":"ok","timestamp":1730429093609,"user_tz":-540,"elapsed":6115,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["## 생성된 본인 얼굴 이미지 데이터 폴더 안의 이미지 수\n","len(os.listdir(extract_folder) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhnix4JZxtAv","executionInfo":{"status":"ok","timestamp":1730429094679,"user_tz":-540,"elapsed":4,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"e3ac18e9-1366-49ea-d630-e735fccd7d05"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2840"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"fCDldok5ySsg"},"source":["#### 2) 다른 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"rITP9F5qeQ5K","executionInfo":{"status":"ok","timestamp":1730429096251,"user_tz":-540,"elapsed":329,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"outputs":[],"source":["data_other = os.path.join(path, 'Datasets/Keras/lfw-deepfunneled.zip')"]},{"cell_type":"code","source":["extract_folder = '/content/other_face'\n","\n","if not os.path.exists(extract_folder):\n","    os.makedirs(extract_folder)\n","\n","with zipfile.ZipFile(data_other, 'r') as zip_ref:\n","    file_list = zip_ref.namelist()\n","\n","    for f in file_list:\n","        if not f.endswith('/') and f.lower().endswith('.jpg'):\n","            file_name = os.path.basename(f)\n","            if not file_name.startswith('._'):\n","                d_path = os.path.join(extract_folder, file_name)\n","                with zip_ref.open(f) as source, open(d_path, 'wb') as target:\n","                    target.write(source.read())\n"],"metadata":{"id":"46sxIuAlxun_","executionInfo":{"status":"ok","timestamp":1730429104711,"user_tz":-540,"elapsed":5164,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["## 생성된 다른 사람 얼굴 이미지 데이터 폴더 안의 이미지 수\n","len(os.listdir(extract_folder) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6p4dYitwxuwX","executionInfo":{"status":"ok","timestamp":1730429104712,"user_tz":-540,"elapsed":4,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"2465a5d8-494a-4b97-989c-940aeb8825d6"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13233"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"G-TovD9FLCCL"},"source":["### (2) 데이터셋 전처리"]},{"cell_type":"markdown","metadata":{"id":"tJPBtHv8LCCL"},"source":["* **세부 요구사항**\n","    - 데이터셋을 전처리 합니다.\n","        - YOLO-cls 모델이 요구하는 폴더 구조를 만듭니다.\n","            1. Datasets라는 폴더를 생성합니다.\n","            2. Training set, Validation set, Test set(선택 사항) 각 데이터셋이 들어갈 폴더를 생성합니다.\n","            3. 각 데이터셋 폴더에 분류할 클래스의 이름을 가진 폴더를 생성합니다.\n","        - 폴더 구조에 맞게 데이터를 분배합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, glob, random, shutil, numpy"]},{"cell_type":"markdown","metadata":{"id":"-_MF4zCRie5X"},"source":["#### 1) 모델이 요하는 구조의 폴더 생성"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"NTzgG1M1eR-A","executionInfo":{"status":"ok","timestamp":1730429109126,"user_tz":-540,"elapsed":4416,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"outputs":[],"source":["import glob\n","import random\n","import shutil\n","import numpy as np\n","\n","from keras.utils import load_img, img_to_array\n","from keras.utils import image_dataset_from_directory"]},{"cell_type":"markdown","metadata":{"id":"wZPds1GraeJ3"},"source":["#### 2) 각 폴더에 이미지 데이터 옮기기"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"VfVQOMf8eTkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730429109126,"user_tz":-540,"elapsed":16,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"b2970d16-03cf-4df9-ed7c-c4c2c28c3503"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n"]}],"source":["## 생성될 폴더의 경로\n","train = '/content/Datasets/train'\n","val = '/content/Datasets/val'\n","test = '/content/Datasets/test'\n","\n","## 폴더가 존재하지 않을 때 폴더를 생성\n","if not os.path.exists(train) :\n","    os.makedirs(train)\n","\n","if not os.path.exists(val) :\n","    os.makedirs(val)\n","\n","if not os.path.exists(test) :\n","    os.makedirs(test)\n","\n","## 폴더 생성 확인\n","print(os.path.exists(train))\n","print(os.path.exists(val))\n","print(os.path.exists(test))"]},{"cell_type":"code","source":["## 생성될 폴더에 대한 하위 폴더 생성\n","class_names = ['my', 'other']\n","\n","for cn in class_names :\n","    temp = os.path.join(train, cn)\n","\n","    if not os.path.exists(temp) :\n","        os.makedirs(temp)\n","\n","    print(os.path.exists(temp))\n","\n","for cn in class_names :\n","    temp = os.path.join(val, cn)\n","\n","    if not os.path.exists(temp) :\n","        os.makedirs(temp)\n","\n","    print(os.path.exists(temp))\n","\n","for cn in class_names :\n","    temp = os.path.join(test, cn)\n","\n","    if not os.path.exists( temp ) :\n","        os.makedirs(temp)\n","\n","    print(os.path.exists(temp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"get1tUAgzqWU","executionInfo":{"status":"ok","timestamp":1730429109127,"user_tz":-540,"elapsed":14,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"c93f2334-dba2-4a57-8426-66cd5c5782b5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n","True\n","True\n","True\n"]}]},{"cell_type":"code","source":["## 본인 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n","img_list_my = sorted(glob.glob('/content/my_face/*',))\n","\n","## 다른 얼굴 데이터가 있는 폴더 경로의 파일 전체를 정렬하여 리스트화\n","img_list_other = sorted(glob.glob('/content/other_face/*'))\n","\n","## 이미지 갯수 확인\n","len(img_list_my), len(img_list_other)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wI-bt2KNzqYe","executionInfo":{"status":"ok","timestamp":1730429109127,"user_tz":-540,"elapsed":10,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"1375bb90-c4bf-4524-ed6a-5b86e0b512f0"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2840, 13233)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["## 얼굴 데이터를 Training set, Test set으로 분할하기 위한 사전 작업\n","## 분할 재현성을 위한 난수 2024 고정\n","random.seed(2024)\n","random.shuffle(img_list_my)\n","random.shuffle(img_list_other)\n","\n","img_list_my[:5], img_list_other[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GTz3KyDzqcK","executionInfo":{"status":"ok","timestamp":1730429110526,"user_tz":-540,"elapsed":2,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"7d2c2faf-2967-4cfc-e614-c7d3aca610b1"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['/content/my_face/my_face_1731.jpg',\n","  '/content/my_face/my_face_2575.jpg',\n","  '/content/my_face/my_face_3199.jpg',\n","  '/content/my_face/my_face_1318.jpg',\n","  '/content/my_face/my_face_2749.jpg'],\n"," ['/content/other_face/Yevgeny_Kafelnikov_0004.jpg',\n","  '/content/other_face/Anibal_Ibarra_0001.jpg',\n","  '/content/other_face/Bob_Hope_0004.jpg',\n","  '/content/other_face/Isabelle_Huppert_0001.jpg',\n","  '/content/other_face/Eddy_Merckx_0002.jpg'])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 비율 설정\n","test_size = 0.2\n","val_size = 0.1\n","\n","# 데이터셋 분할 및 파일 복사\n","for i_l in [img_list_my, img_list_other]:\n","    list_len = len(i_l)\n","\n","    # Index 설정\n","    test_idx = int(list_len * (1 - test_size))  # 전체 중에서 상위 80%까지 사용 (20%는 test)\n","    val_idx = int(test_idx * (1 - val_size / (1 - test_size)))  # 상위 80% 중에서 10% 사용 (전체의 10%)\n","\n","    # Training, Validation, Test\n","    list_tr = i_l[:val_idx]\n","    list_val = i_l[val_idx:test_idx]\n","    list_te = i_l[test_idx:]\n","\n","    # my\n","    if i_l == img_list_my:\n","        for file_path in list_tr:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, train + '/my/' + f_name)\n","\n","        for file_path in list_val:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, val + '/my/' + f_name)\n","\n","        for file_path in list_te:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, test + '/my/' + f_name)\n","\n","    # other\n","    else:\n","        for file_path in list_tr:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, train + '/other/' + f_name)\n","\n","        for file_path in list_val:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, val + '/other/' + f_name)\n","\n","        for file_path in list_te:\n","            f_name = file_path.split('/')[-1]\n","            shutil.copy(file_path, test + '/other/' + f_name)"],"metadata":{"id":"l71rXVQ50Jhe","executionInfo":{"status":"ok","timestamp":1730429114666,"user_tz":-540,"elapsed":2854,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# 분할 및 길이 확인 함수\n","def split_data_and_copy(img_list, train_folder, valid_folder, test_folder, class_name):\n","    list_len = len(img_list)\n","\n","    # Index 설정\n","    test_idx = int(list_len * (1 - test_size))         # Test set은 상위 80%까지\n","    val_idx = int(list_len * (1 - test_size - val_size))  # Validation set은 상위 90%까지\n","\n","    # Training, Validation, Test 세분화\n","    list_tr = img_list[:val_idx]\n","    list_val = img_list[val_idx:test_idx]\n","    list_te = img_list[test_idx:]\n","\n","    # 각 셋의 길이 출력\n","    print(f\"{class_name} 데이터셋 분할 결과:\")\n","    print(f\"Training set: {len(list_tr)}\")\n","    print(f\"Validation set: {len(list_val)}\")\n","    print(f\"Test set: {len(list_te)}\")\n","    print(\"=\"*30)\n","\n","    # 파일 복사\n","    for file_path in list_tr:\n","        f_name = file_path.split('/')[-1]\n","        shutil.copy(file_path, os.path.join(train_folder, class_name, f_name))\n","\n","    for file_path in list_val:\n","        f_name = file_path.split('/')[-1]\n","        shutil.copy(file_path, os.path.join(valid_folder, class_name, f_name))\n","\n","    for file_path in list_te:\n","        f_name = file_path.split('/')[-1]\n","        shutil.copy(file_path, os.path.join(test_folder, class_name, f_name))"],"metadata":{"id":"4UqyFfXM2j9R","executionInfo":{"status":"ok","timestamp":1730429115921,"user_tz":-540,"elapsed":5,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# my\n","split_data_and_copy(img_list_my, train, val, test, 'my')\n","\n","# other\n","split_data_and_copy(img_list_other, train, val, test, 'other')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWhL-1tNzqen","executionInfo":{"status":"ok","timestamp":1730429121880,"user_tz":-540,"elapsed":3608,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"outputId":"66680abc-9f6c-416d-c965-96ec313cc2a4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["my 데이터셋 분할 결과:\n","Training set: 1988\n","Validation set: 284\n","Test set: 568\n","==============================\n","other 데이터셋 분할 결과:\n","Training set: 9263\n","Validation set: 1323\n","Test set: 2647\n","==============================\n"]}]},{"cell_type":"markdown","metadata":{"id":"w59u5Dtnrh5h"},"source":["## 3.미션2"]},{"cell_type":"markdown","metadata":{"id":"JHu91EoOrh2Q"},"source":["데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"AygPItZba0TI"},"source":["#### (1) UltraLytics YOLO-cls 모델 선택"]},{"cell_type":"markdown","metadata":{"id":"E7zOy5GfbMTR"},"source":["* **세부 요구사항**\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ULEjDkdUGhCz","executionInfo":{"status":"ok","timestamp":1730429151151,"user_tz":-540,"elapsed":10203,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"762674c8-490b-4c49-87af-defd147180da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.52M/5.52M [00:00<00:00, 112MB/s]\n"]}],"source":["from ultralytics import YOLO\n","\n","model = YOLO(\"yolo11n-cls.pt\")"]},{"cell_type":"markdown","metadata":{"id":"X7rqg7bda6Uz"},"source":["#### (2) UltraLytics YOLO-cls 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"48UKFtS6bc9b"},"source":["* **세부 요구사항**\n","    - 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"]},{"cell_type":"code","source":["# # data.yaml 파일\n","# yaml_content = \"\"\"\n","# train: /content/Datasets/train\n","# val: /content/Datasets/valid\n","# test: /content/Datasets/test\n","\n","# names:\n","#   0: my\n","#   1: other\n","# \"\"\"\n","\n","# with open('/content/data.yaml', 'w') as file:\n","#     file.write(yaml_content)\n","# model.train(data=\"/content/Datasets/train\", epochs=100, imgsz=640)"],"metadata":{"id":"mL7VjbHNBVW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train(data=\"/content/Datasets\", epochs=10, imgsz=160, patience=3, optimizer='NAdam', lr0=0.001)"],"metadata":{"id":"EWQ4MCVp4CM3","executionInfo":{"status":"ok","timestamp":1730430138184,"user_tz":-540,"elapsed":783998,"user":{"displayName":"킹승영","userId":"12420221722795178737"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10e0e787-2f0a-4063-adbf-231baebe7851"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.27 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=/content/Datasets, epochs=10, time=None, patience=3, batch=16, imgsz=160, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=NAdam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 11251 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 1608 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3215 images in 2 classes ✅ \n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n","YOLO11n-cls summary: 151 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n","Transferred 234/236 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 95.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Datasets/train... 11251 images, 0 corrupt: 100%|██████████| 11251/11251 [00:02<00:00, 3928.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Datasets/train.cache\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/val... 1608 images, 0 corrupt: 100%|██████████| 1608/1608 [00:00<00:00, 1691.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Datasets/val.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m NAdam(lr=0.001, momentum=0.937) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 160 train, 160 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/classify/train\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/10     0.226G     0.2441         16        160:   1%|          | 6/704 [00:01<01:58,  5.89it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["       1/10     0.226G     0.1383         16        160:   2%|▏         | 16/704 [00:02<01:09,  9.89it/s]\n","100%|██████████| 755k/755k [00:00<00:00, 19.2MB/s]\n","       1/10     0.231G    0.01991          3        160: 100%|██████████| 704/704 [01:15<00:00,  9.38it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 13.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/10     0.201G     0.0108          3        160: 100%|██████████| 704/704 [01:12<00:00,  9.65it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:05<00:00,  8.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/10     0.201G    0.01235          3        160: 100%|██████████| 704/704 [01:07<00:00, 10.40it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 13.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/10     0.201G   0.007447          3        160: 100%|██████████| 704/704 [01:11<00:00,  9.90it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 14.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/10     0.201G   0.003698          3        160: 100%|██████████| 704/704 [01:13<00:00,  9.55it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:04<00:00, 11.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/10     0.201G   0.001359          3        160: 100%|██████████| 704/704 [01:07<00:00, 10.46it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:05<00:00,  9.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/10     0.201G  0.0008341          3        160: 100%|██████████| 704/704 [01:09<00:00, 10.10it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 15.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/10     0.201G  0.0004456          3        160: 100%|██████████| 704/704 [01:14<00:00,  9.47it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 15.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/10     0.201G  0.0002825          3        160: 100%|██████████| 704/704 [01:09<00:00, 10.13it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:03<00:00, 12.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/10     0.201G   0.000169          3        160: 100%|██████████| 704/704 [01:07<00:00, 10.41it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:05<00:00,  9.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","10 epochs completed in 0.212 hours.\n","Optimizer stripped from runs/classify/train/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/train/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/train/weights/best.pt...\n","Ultralytics 8.3.27 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLO11n-cls summary (fused): 112 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 11251 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 1608 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3215 images in 2 classes ✅ \n"]},{"output_type":"stream","name":"stderr","text":["               classes   top1_acc   top5_acc: 100%|██████████| 51/51 [00:06<00:00,  8.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n","\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f01419fa320>\n","curves: []\n","curves_results: []\n","fitness: 1.0\n","keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n","results_dict: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n","save_dir: PosixPath('runs/classify/train')\n","speed: {'preprocess': 0.05267375144199352, 'inference': 0.7317822370956193, 'loss': 0.0004259804588052171, 'postprocess': 0.0004141188379543931}\n","task: 'classify'\n","top1: 1.0\n","top5: 1.0"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model.save(\"custom_model_params_10.pt\")"],"metadata":{"id":"TQSzAIPBwQKk","executionInfo":{"status":"ok","timestamp":1730430161274,"user_tz":-540,"elapsed":644,"user":{"displayName":"킹승영","userId":"12420221722795178737"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UsxBhoAubn2u"},"source":["#### (3) UltraLytics YOLO-cls 추론"]},{"cell_type":"markdown","metadata":{"id":"wPtTHcnbbn2u"},"source":["* **세부 요구사항**\n","    - 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"Dnip8w5V0z44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test 폴더 내 'my'와 'other' 하위 폴더 경로 설정\n","test_my_dir = '/content/Datasets/test/my'\n","test_other_dir = '/content/Datasets/test/other'\n","\n","# 'my'와 'other' 폴더 내 모든 이미지 파일 목록 불러오기\n","all_images = []\n","for folder in [test_my_dir, test_other_dir]:\n","    all_images += [os.path.join(folder, img) for img in os.listdir(folder) if img.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# 이미지가 10개 이상일 경우 10개를 랜덤 선택, 그렇지 않으면 전체 사용\n","random_images = random.sample(all_images, min(10, len(all_images)))\n","\n","# 선택된 이미지에 대해 추론\n","results = model.predict(source=random_images)\n","\n","# 시각화 설정\n","plt.figure(figsize=(15, 15))\n","for idx, result in enumerate(results):\n","    # 예측 클래스와 확률 가져오기\n","    predicted_class = result.names[result.probs.top1]  # 클래스 이름\n","    confidence_score = result.probs.top1conf.item()  # 해당 클래스의 확률\n","    img = result.orig_img[:, :, ::-1]  # BGR -> RGB로 변환\n","\n","    # 서브플롯에 이미지 표시\n","    ax = plt.subplot(4, 5, idx + 1)\n","    ax.imshow(img.astype(\"uint8\"))\n","    ax.set_title(f\"Class: {predicted_class} | Conf: {confidence_score:.2f}\")\n","    ax.axis(\"off\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"collapsed":true,"id":"vN4BCYbx0vR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","test_images = glob.glob('/content/Datasets/test/*/*.jpg', recursive=True)"],"metadata":{"id":"Kr26TqDqp3Aj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = model.predict(source=test_images, save=True)"],"metadata":{"id":"6li1oysdE_pp","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OUAH3GxZwT46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ytKJsOUGhC0"},"source":["#### (4) UltraLytics YOLO-cls 모델 저장"]},{"cell_type":"markdown","metadata":{"id":"VkC4WP-8cA7g"},"source":["* **세부 요구사항**\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMLUGduLGhC0"},"outputs":[],"source":["# model.save(\"custom_model.pt\")\n","# model.save(\"custom_model_1.pt\")\n","model.save(\"custom_model_10.pt\")"]},{"cell_type":"code","source":["# temp_model = YOLO(\"custom_model.pt\")\n","temp_model = YOLO(\"custom_model_10.pt\")\n","temp_model"],"metadata":{"collapsed":true,"id":"I5t9RHLlCVqJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IjMMUjFCzoJh"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}